global:
  image:
    registry: null
  priorityClassName: null
  clusterDomain: "cluster.local"
  dnsService: "kube-dns"
  dnsNamespace: "kube-system"

nameOverride: null
fullnameOverride: null
imagePullSecrets: []
hostAliases: []
loki:
  annotations: {}
  readinessProbe:
    httpGet:
      path: /ready
      port: http
    initialDelaySeconds: 30
    timeoutSeconds: 1
  livenessProbe:
    httpGet:
      path: /ready
      port: http
    initialDelaySeconds: 300
  image:
    registry: docker.io
    repository: grafana/loki
    tag: null
    pullPolicy: IfNotPresent
  podLabels: {}
  podAnnotations: {}
  command: null
  revisionHistoryLimit: 10
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
  containerSecurityContext:
    readOnlyRootFilesystem: false
    capabilities:
      drop:
        - ALL
    allowPrivilegeEscalation: false
  existingSecretForConfig: ""
  configAsSecret: true
  configSecretAnnotations: {}
  configSecretLabels: {}
  appProtocol: "tcp"
  serviceAnnotations: {}
  server:
    http_listen_port: 3100
  
  # 수정
  # chunk_idle_period : 얼마나 자주 Flush해서 Chunk파일을 오브젝트 스토리지에 저장할 것인지
  # chunk_block_size : 어느 사이즈 이상을 초과하면 Flush해서 Chunk파일로 만들지
  config: |
    auth_enabled: false

    server:
      {{- toYaml .Values.loki.server | nindent 6 }}

    common:
      compactor_address: http://{{ include "loki.compactorFullname" . }}:3100

    distributor:
      ring:
        kvstore:
          store: memberlist

    memberlist:
      join_members:
        - {{ include "loki.fullname" . }}-memberlist

    ingester_client:
      grpc_client_config:
        grpc_compression: gzip

    ingester:
      lifecycler:
        ring:
          kvstore:
            store: memberlist
          replication_factor: 1
      chunk_idle_period: 2h 
      chunk_block_size: 262144
      chunk_encoding: snappy
      chunk_retain_period: 1m
      max_transfer_retries: 0
      wal:
        dir: loki/wal

    limits_config:
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      max_cache_freshness_per_query: 10m
      split_queries_by_interval: 15m

    {{- if .Values.loki.schemaConfig}}
    schema_config:
    {{- toYaml .Values.loki.schemaConfig | nindent 2}}
    {{- end}}
    {{- if .Values.loki.storageConfig}}
    storage_config:
    {{- if .Values.indexGateway.enabled}}
    {{- $indexGatewayClient := dict "server_address" (printf "dns:///%s:9095" (include "loki.indexGatewayFullname" .)) }}
    {{- $_ := set .Values.loki.storageConfig.boltdb_shipper "index_gateway_client" $indexGatewayClient }}
    {{- end}}
    {{- toYaml .Values.loki.storageConfig | nindent 2}}
    {{- if .Values.memcachedIndexQueries.enabled }}
      index_queries_cache_config:
        memcached_client:
          addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedIndexQueriesFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
          consistent_hash: true
    {{- end}}
    {{- end}}

    runtime_config:
      file: /var/{{ include "loki.name" . }}-runtime/runtime.yaml

    chunk_store_config:
      max_look_back_period: 0s
      {{- if .Values.memcachedChunks.enabled }}
      chunk_cache_config:
        embedded_cache:
          enabled: false
        memcached_client:
          consistent_hash: true
          addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedChunksFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
      {{- end }}
      {{- if .Values.memcachedIndexWrites.enabled }}
      write_dedupe_cache_config:
        memcached_client:
          consistent_hash: true
          addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedIndexWritesFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
      {{- end }}

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

    query_range:
      align_queries_with_step: true
      max_retries: 5
      cache_results: true
      results_cache:
        cache:
          {{- if .Values.memcachedFrontend.enabled }}
          memcached_client:
            addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedFrontendFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
            consistent_hash: true
          {{- else }}
          embedded_cache:
            enabled: true
            ttl: 24h
          {{- end }}

    frontend_worker:
      {{- if .Values.queryScheduler.enabled }}
      scheduler_address: {{ include "loki.querySchedulerFullname" . }}:9095
      {{- else }}
      frontend_address: {{ include "loki.queryFrontendFullname" . }}-headless:9095
      {{- end }}

    frontend:
      log_queries_longer_than: 5s
      compress_responses: true
      {{- if .Values.queryScheduler.enabled }}
      scheduler_address: {{ include "loki.querySchedulerFullname" . }}:9095
      {{- end }}
      tail_proxy_url: http://{{ include "loki.querierFullname" . }}:3100

    compactor:
      shared_store: filesystem
      working_directory: /var/loki/compactor

    ruler:
      storage:
        type: local
        local:
          directory: /etc/loki/rules
      ring:
        kvstore:
          store: memberlist
      rule_path: /tmp/loki/scratch
      alertmanager_url: https://alertmanager.xx
      external_url: https://alertmanager.xx

  schemaConfig:
    configs:
    - from: "2020-09-07"
      store: boltdb-shipper
      object_store: s3
      schema: v11
      index:
        prefix: loki_index_
        period: 24h

  storageConfig:
    aws:
      # 수정, http://{AccessKey}:{SecretKey}@{Host}:{Port}/{BucketName}
      s3: http://console:console123@minio-wl.plg-system.svc.cluster.local:9000/testbucket
      s3forcepathstyle: true # 수정, true로 설정해야 위에서 입력한 URL을 그대로 사용 가능합니다.
      region: "ap-northeast-2" # 수정, MinIO 콘솔에서 설정한 Region을 입력하시면 됩니다.
    boltdb_shipper:
      active_index_directory: /loki/index
      shared_store: s3 # 수정
      cache_location: /loki/boltdb-cache

  structuredConfig: {}

runtimeConfig: {}
serviceAccount:
  create: true
  name: null
  imagePullSecrets: []
  labels: {}
  annotations: {}
  automountServiceAccountToken: true

rbac:
  pspEnabled: false
  sccEnabled: false

serviceMonitor:
  enabled: false
  namespace: null
  namespaceSelector: {}
  matchExpressions: []
  annotations: {}
  labels: {}
  interval: null
  scrapeTimeout: null
  relabelings: []
  metricRelabelings: []
  targetLabels: []
  scheme: http
  tlsConfig: null

prometheusRule:
  enabled: false
  namespace: null
  annotations: {}
  labels: {}
  groups: []

ingester:
  kind: StatefulSet # or Deployment
  replicas: 3
  hostAliases: []
  autoscaling:
    enabled: false
    minReplicas: 3
    maxReplicas: 10
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: 60
    customMetrics: []
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
  image:
    registry: null
    repository: null
    tag: null
  command: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  initContainers: []
  terminationGracePeriodSeconds: 300
  lifecycle: {}
  topologySpreadConstraints: []
    # |
    # - maxSkew: 1
    #   topologyKey: kubernetes.io/hostname
    #   whenUnsatisfiable: ScheduleAnyway
    #   labelSelector:
    #     matchLabels:
    #       {{- include "loki.ingesterSelectorLabels" . | nindent 6 }}
  affinity: {}
    # |
    # podAntiAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #     - labelSelector:
    #         matchLabels:
    #           {{- include "loki.ingesterSelectorLabels" . | nindent 10 }}
    #       topologyKey: kubernetes.io/hostname
    #   preferredDuringSchedulingIgnoredDuringExecution:
    #     - weight: 100
    #       podAffinityTerm:
    #         labelSelector:
    #           matchLabels:
    #             {{- include "loki.ingesterSelectorLabels" . | nindent 12 }}
    #         topologyKey: failure-domain.beta.kubernetes.io/zone
  maxUnavailable: null
  maxSurge: 0
  nodeSelector: {}
  tolerations: []
  readinessProbe: {}
  livenessProbe: {}
  persistence:
    enabled: true
    inMemory: false
    claims:
      - name: ingester-pvc # 수정
        size: 10Gi # 수정
        storageClass: rook-cephfs-retain # 수정
    enableStatefulSetAutoDeletePVC: false
    whenDeleted: Retain
    whenScaled: Retain
  appProtocol:
    grpc: ""

distributor:
  replicas: 3
  hostAliases: []
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
    customMetrics: []
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
  image:
    registry: null
    repository: null
    tag: null
  command: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  maxUnavailable: null
  maxSurge: 0
  nodeSelector: {}
  tolerations: []
  appProtocol:
    grpc: ""

querier:
  replicas: 3
  hostAliases: []
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
    customMetrics: []
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
  image:
    registry: null
    repository: null
    tag: null
  command: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  initContainers: []
  terminationGracePeriodSeconds: 30
  topologySpreadConstraints: {}
  affinity: {}
  maxUnavailable: null
  maxSurge: 0
  nodeSelector: {}
  tolerations: []
  dnsConfig: {}
  persistence:
    enabled: false
    size: 10Gi
    storageClass: null
    annotations: {}
  appProtocol:
    grpc: ""

queryFrontend:
  replicas: 2
  hostAliases: []
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
    customMetrics: []
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
  image:
    registry: null
    repository: null
    tag: null
  command: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  #   |
  #   podAntiAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       - labelSelector:
  #           matchLabels:
  #             {{- include "loki.queryFrontendSelectorLabels" . | nindent 10 }}
  #         topologyKey: kubernetes.io/hostname
  #     preferredDuringSchedulingIgnoredDuringExecution:
  #       - weight: 100
  #         podAffinityTerm:
  #           labelSelector:
  #             matchLabels:
  #               {{- include "loki.queryFrontendSelectorLabels" . | nindent 12 }}
  #           topologyKey: failure-domain.beta.kubernetes.io/zone
  maxUnavailable: null
  nodeSelector: {}
  tolerations: []
  appProtocol:
    grpc: ""

queryScheduler:
  enabled: true
  replicas: 1
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
    # |
    # podAntiAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #     - labelSelector:
    #         matchLabels:
    #           {{- include "loki.querySchedulerSelectorLabels" . | nindent 10 }}
    #       topologyKey: kubernetes.io/hostname
    #   preferredDuringSchedulingIgnoredDuringExecution:
    #     - weight: 100
    #       podAffinityTerm:
    #         labelSelector:
    #           matchLabels:
    #             {{- include "loki.querySchedulerSelectorLabels" . | nindent 12 }}
    #         topologyKey: failure-domain.beta.kubernetes.io/zone
  maxUnavailable: 1
  nodeSelector: {}
  tolerations: []
  appProtocol:
    grpc: ""

tableManager:
  enabled: false
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  command: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  nodeSelector: {}
  tolerations: []

ingress:
  enabled: false
  annotations: {}
  paths:
    distributor: []
    querier: []
    query-frontend: []
    ruler: []
  hosts: []

gateway:
  enabled: true
  hostAliases: []
  replicas: 1
  verboseLogging: true
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
    customMetrics: []
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
  deploymentStrategy:
    type: RollingUpdate
  image:
    registry: docker.io
    repository: nginxinc/nginx-unprivileged
    tag: 1.20.2-alpine
    pullPolicy: IfNotPresent
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumes: []
  extraVolumeMounts: []
  podSecurityContext:
    fsGroup: 101
    runAsGroup: 101
    runAsNonRoot: true
    runAsUser: 101
  containerSecurityContext:
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    allowPrivilegeEscalation: false
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  maxUnavailable: null
  nodeSelector: {}
  tolerations: []
  dnsConfig: {}
  service:
    port: 80
    type: ClusterIP
    clusterIP: null
    nodePort: null
    loadBalancerIP: null
    loadBalancerSourceRanges: []
    appProtocol: null
    annotations: {}
    labels: {}
  ingress:
    enabled: false
    ingressClassName: ''
    annotations: {}
    hosts: []
    tls: []

  basicAuth:
    enabled: true # 수정
    username: "admin" # 수정, 이 username을 통해 Promtail이 Loki에 접근할 수 있게됩니다.
    password: "admin" # 수정, 이 password를 통해 Promtail이 Loki에 접근할 수 있게됩니다.
    htpasswd: >-
      {{ htpasswd (required "'gateway.basicAuth.username' is required" .Values.gateway.basicAuth.username) (required "'gateway.basicAuth.password' is required" .Values.gateway.basicAuth.password) }}
    existingSecret: null
  readinessProbe:
    httpGet:
      path: /
      port: http
    initialDelaySeconds: 15
    timeoutSeconds: 1
  livenessProbe:
    httpGet:
      path: /
      port: http
    initialDelaySeconds: 30
  nginxConfig:
    logFormat: |-
      main '$remote_addr - $remote_user [$time_local]  $status '
              '"$request" $body_bytes_sent "$http_referer" '
              '"$http_user_agent" "$http_x_forwarded_for"';
    serverSnippet: ""
    httpSnippet: ""
    resolver: ""
    file: |
      worker_processes  5;  ## Default: 1
      error_log  /dev/stderr;
      pid        /tmp/nginx.pid;
      worker_rlimit_nofile 8192;

      events {
        worker_connections  4096;  ## Default: 1024
      }

      http {
        client_body_temp_path /tmp/client_temp;
        proxy_temp_path       /tmp/proxy_temp_path;
        fastcgi_temp_path     /tmp/fastcgi_temp;
        uwsgi_temp_path       /tmp/uwsgi_temp;
        scgi_temp_path        /tmp/scgi_temp;

        proxy_http_version    1.1;

        default_type application/octet-stream;
        log_format   {{ .Values.gateway.nginxConfig.logFormat }}

        {{- if .Values.gateway.verboseLogging }}
        access_log   /dev/stderr  main;
        {{- else }}

        map $status $loggable {
          ~^[23]  0;
          default 1;
        }
        access_log   /dev/stderr  main  if=$loggable;
        {{- end }}

        sendfile     on;
        tcp_nopush   on;
        {{- if .Values.gateway.nginxConfig.resolver }}
        resolver {{ .Values.gateway.nginxConfig.resolver }};
        {{- else }}
        resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};
        {{- end }}

        {{- with .Values.gateway.nginxConfig.httpSnippet }}
        {{ . | nindent 2 }}
        {{- end }}

        server {
          listen             8080;

          {{- if .Values.gateway.basicAuth.enabled }}
          auth_basic           "Loki";
          auth_basic_user_file /etc/nginx/secrets/.htpasswd;
          {{- end }}

          location = / {
            return 200 'OK';
            auth_basic off;
            access_log off;
          }

          location = /api/prom/push {
            set $api_prom_push_backend http://{{ include "loki.distributorFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass       $api_prom_push_backend:3100$request_uri;
            proxy_http_version 1.1;
          }

          location = /api/prom/tail {
            set $api_prom_tail_backend http://{{ include "loki.querierFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass       $api_prom_tail_backend:3100$request_uri;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_http_version 1.1;
          }

          # Ruler
          location ~ /prometheus/api/v1/alerts.* {
            proxy_pass       http://{{ include "loki.rulerFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }
          location ~ /prometheus/api/v1/rules.* {
            proxy_pass       http://{{ include "loki.rulerFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }
          location ~ /api/prom/rules.* {
            proxy_pass       http://{{ include "loki.rulerFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }
          location ~ /api/prom/alerts.* {
            proxy_pass       http://{{ include "loki.rulerFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }

          location ~ /api/prom/.* {
            set $api_prom_backend http://{{ include "loki.queryFrontendFullname" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass       $api_prom_backend:3100$request_uri;
            proxy_http_version 1.1;
          }

          location = /loki/api/v1/push {
            set $loki_api_v1_push_backend http://{{ include "loki.distributorFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass       $loki_api_v1_push_backend:3100$request_uri;
            proxy_http_version 1.1;
          }

          location = /loki/api/v1/tail {
            set $loki_api_v1_tail_backend http://{{ include "loki.querierFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass       $loki_api_v1_tail_backend:3100$request_uri;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_http_version 1.1;
          }

          location ~ /loki/api/.* {
            set $loki_api_backend http://{{ include "loki.queryFrontendFullname" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass       $loki_api_backend:3100$request_uri;
            proxy_http_version 1.1;
          }

          {{- with .Values.gateway.nginxConfig.serverSnippet }}
          {{ . | nindent 4 }}
          {{- end }}
        }
      }

compactor:
  kind: Deployment
  replicas: 1
  enabled: false
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  command: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  affinity: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  readinessProbe: {}
  livenessProbe: {}
  resources: {}
  extraContainers: []
  initContainers: []
  terminationGracePeriodSeconds: 30
  nodeSelector: {}
  tolerations: []
  appProtocol:
    grpc: ""
  persistence:
    enabled: false
    size: 10Gi
    storageClass: null
    annotations: {}
    claims:
      - name: data
        size: 10Gi
        storageClass: null
    enableStatefulSetAutoDeletePVC: false
    whenDeleted: Retain
    whenScaled: Retain

  serviceAccount:
    create: false
    name: null
    imagePullSecrets: []
    annotations: {}
    automountServiceAccountToken: true

ruler:
  enabled: false
  kind: Deployment
  replicas: 1
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  command: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  initContainers: []
  terminationGracePeriodSeconds: 300
  affinity: {}
  maxUnavailable: null
  nodeSelector: {}
  tolerations: []
  dnsConfig: {}
  persistence:
    enabled: false
    size: 10Gi
    storageClass: null
    annotations: {}
  appProtocol:
    grpc: ""
  directories: {}

indexGateway:
  enabled: false
  replicas: 1
  joinMemberlist: true
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  resources: {}
  extraContainers: []
  initContainers: []
  terminationGracePeriodSeconds: 300
  affinity: {}
  maxUnavailable: null
  nodeSelector: {}
  tolerations: []
  persistence:
    enabled: false
    inMemory: false
    size: 10Gi
    storageClass: null
    annotations: {}
    enableStatefulSetAutoDeletePVC: false
    whenDeleted: Retain
    whenScaled: Retain
  appProtocol:
    grpc: ""

memcached:
  readinessProbe:
    tcpSocket:
      port: http
    initialDelaySeconds: 5
    timeoutSeconds: 1
  livenessProbe:
    tcpSocket:
      port: http
    initialDelaySeconds: 10
  image:
    registry: docker.io
    repository: memcached
    tag: 1.6.21-alpine
    pullPolicy: IfNotPresent
  podLabels: {}
  podSecurityContext:
    fsGroup: 11211
    runAsGroup: 11211
    runAsNonRoot: true
    runAsUser: 11211
  containerSecurityContext:
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    allowPrivilegeEscalation: false
  serviceAnnotations: {}
  appProtocol: ""

memcachedExporter:
  enabled: false
  image:
    registry: docker.io
    repository: prom/memcached-exporter
    tag: v0.13.0
    pullPolicy: IfNotPresent
  podLabels: {}
  resources: {}
  containerSecurityContext:
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    allowPrivilegeEscalation: false

memcachedChunks:
  enabled: false
  hostAliases: []
  replicas: 1
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs:
    - -I 32m
  extraEnv: []
  extraEnvFrom: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  maxUnavailable: null
  nodeSelector: {}
  tolerations: []
  persistence:
    enabled: false
    size: 10Gi
    storageClass: null
  volumeClaimTemplates: []
  extraVolumeMounts: []

memcachedFrontend:
  enabled: false
  hostAliases: []
  replicas: 1
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs:
    - -I 32m
  extraEnv: []
  extraEnvFrom: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  maxUnavailable: 1
  nodeSelector: {}
  tolerations: []
  persistence:
    enabled: false
    size: 10Gi
    storageClass: null

memcachedIndexQueries:
  enabled: false
  replicas: 1
  hostAliases: []
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs:
    - -I 32m
  extraEnv: []
  extraEnvFrom: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  maxUnavailable: null
  nodeSelector: {}
  tolerations: []
  persistence:
    enabled: false
    size: 10Gi
    storageClass: null

memcachedIndexWrites:
  enabled: false
  replicas: 1
  hostAliases: []
  priorityClassName: null
  podLabels: {}
  podAnnotations: {}
  serviceLabels: {}
  extraArgs:
    - -I 32m
  extraEnv: []
  extraEnvFrom: []
  resources: {}
  extraContainers: []
  terminationGracePeriodSeconds: 30
  affinity: {}
  maxUnavailable: null
  nodeSelector: {}
  tolerations: []
  persistence:
    enabled: false
    size: 10Gi
    storageClass: null

networkPolicy:
  enabled: false
  metrics:
    podSelector: {}
    namespaceSelector: {}
    cidrs: []
  ingress:
    podSelector: {}
    namespaceSelector: {}
  alertmanager:
    port: 9093
    podSelector: {}
    namespaceSelector: {}
  externalStorage:
    ports: []
    cidrs: []
  discovery:
    port: null
    podSelector: {}
    namespaceSelector: {}